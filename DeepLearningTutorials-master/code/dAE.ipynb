{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling  normalized_data.h5 ......\n",
      "... loading data\n",
      "Printing Train set  [[-0.01192936  0.04222802  0.02708294 ..., -0.19124368 -0.10504689\n",
      "  -0.15137926]\n",
      " [-0.01057465 -0.14316248 -0.10411913 ..., -0.01485521  0.01530538\n",
      "   0.06022365]\n",
      " [ 0.0557068   0.27179684  0.19131898 ...,  0.08482909  0.10881923\n",
      "   0.03820324]\n",
      " ..., \n",
      " [-0.01017692 -0.12107509 -0.13732674 ..., -0.02985386 -0.12656212\n",
      "  -0.09359577]\n",
      " [-0.02024922 -0.02451657  0.08745872 ..., -0.02140495 -0.0060667\n",
      "  -0.02612032]\n",
      " [-0.04439969 -0.1769916  -0.20425011 ...,  0.08570087 -0.07248146\n",
      "  -0.05293814]]\n",
      "X_train shape  (1000, 16384)\n",
      "Printing shared_dataset  <TensorType(float64, matrix)>\n",
      "Final Training Set  <TensorType(float64, matrix)>\n",
      "<TensorType(float64, matrix)>\n",
      "Building model with 0 percent Corruption...... \n"
     ]
    },
    {
     "ename": "MissingInputError",
     "evalue": "(\"An input of the graph, used to compute Shape(x), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", x)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m\u001b[0m",
      "\u001b[1;31mMissingInputError\u001b[0mTraceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3385df7eced0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    396\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m     \u001b[0mtest_dA\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3385df7eced0>\u001b[0m in \u001b[0;36mtest_dA\u001b[1;34m(learning_rate, training_epochs, dataset, batch_size, output_folder)\u001b[0m\n\u001b[0;32m    333\u001b[0m     cost, updates = da.get_cost_updates(\n\u001b[0;32m    334\u001b[0m         \u001b[0mcorruption_level\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcorruption_level\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         \u001b[0mlearning_rate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m     )\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-3385df7eced0>\u001b[0m in \u001b[0;36mget_cost_updates\u001b[1;34m(self, corruption_level, learning_rate)\u001b[0m\n\u001b[0;32m    241\u001b[0m         \u001b[0mtilde_x\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_corrupted_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcorruption_level\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_hidden_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtilde_x\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"hidden Shape : \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    244\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[0mz\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_reconstructed_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/gof/graph.py\u001b[0m in \u001b[0;36meval\u001b[1;34m(self, inputs_to_values)\u001b[0m\n\u001b[0;32m    410\u001b[0m         \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    411\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0minputs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 412\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fn_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    413\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0minputs_to_values\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mparam\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    414\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/compile/function.py\u001b[0m in \u001b[0;36mfunction\u001b[1;34m(inputs, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    264\u001b[0m                 \u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mallow_input_downcast\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    265\u001b[0m                 \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 266\u001b[1;33m                 profile=profile)\n\u001b[0m\u001b[0;32m    267\u001b[0m     \u001b[1;31m# We need to add the flag check_aliased inputs if we have any mutable or\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    268\u001b[0m     \u001b[1;31m# borrowed used defined inputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/compile/pfunc.py\u001b[0m in \u001b[0;36mpfunc\u001b[1;34m(params, outputs, mode, updates, givens, no_default_updates, accept_inplace, name, rebuild_strict, allow_input_downcast, profile, on_unused_input)\u001b[0m\n\u001b[0;32m    509\u001b[0m     return orig_function(inputs, cloned_outputs, mode,\n\u001b[0;32m    510\u001b[0m             \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m             on_unused_input=on_unused_input)\n\u001b[0m\u001b[0;32m    512\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36morig_function\u001b[1;34m(inputs, outputs, mode, accept_inplace, name, profile, on_unused_input)\u001b[0m\n\u001b[0;32m   1463\u001b[0m                    \u001b[0maccept_inplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_inplace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1464\u001b[0m                    \u001b[0mprofile\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprofile\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1465\u001b[1;33m                    \u001b[0mon_unused_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mon_unused_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1466\u001b[0m                        defaults)\n\u001b[0;32m   1467\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, mode, accept_inplace, function_builder, profile, on_unused_input, fgraph)\u001b[0m\n\u001b[0;32m   1131\u001b[0m             \u001b[0mneed_opt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m             \u001b[1;31m# make the fgraph (copies the graph, creates NEW INPUT AND OUTPUT VARIABLES)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1133\u001b[1;33m             \u001b[0mfgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madditional_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstd_fgraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_inplace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1134\u001b[0m             \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofile\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprofile\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1135\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36mstd_fgraph\u001b[1;34m(input_specs, output_specs, accept_inplace)\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[0morig_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariable\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mspec\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moutput_specs\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mupdates\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m     \u001b[0mfgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFunctionGraph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0morig_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morig_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, inputs, outputs, features, clone)\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import_r__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"init\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m             \u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclients\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__import_r__\u001b[1;34m(self, variables, reason)\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    256\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mapply_node\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 257\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__import__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mapply_node\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreason\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreason\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    258\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvariables\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    259\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mowner\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConstant\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/anaconda3/lib/python3.5/site-packages/theano/gof/fg.py\u001b[0m in \u001b[0;36m__import__\u001b[1;34m(self, apply_node, check, reason)\u001b[0m\n\u001b[0;32m    360\u001b[0m                             \u001b[1;34m\"for more information on this error.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m                             % str(node)),\n\u001b[1;32m--> 362\u001b[1;33m                             r)\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mnode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnew_nodes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMissingInputError\u001b[0m: (\"An input of the graph, used to compute Shape(x), was not provided and not given a value.Use the Theano flag exception_verbosity='high',for more information on this error.\", x)"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " This tutorial introduces denoising auto-encoders (dA) using Theano.\n",
    "\n",
    " Denoising autoencoders are the building blocks for SdA.\n",
    " They are based on auto-encoders as the ones used in Bengio et al. 2007.\n",
    " An autoencoder takes an input x and first maps it to a hidden representation\n",
    " y = f_{\\theta}(x) = s(Wx+b), parameterized by \\theta={W,b}. The resulting\n",
    " latent representation y is then mapped back to a \"reconstructed\" vector\n",
    " z \\in [0,1]^d in input space z = g_{\\theta'}(y) = s(W'y + b').  The weight\n",
    " matrix W' can optionally be constrained such that W' = W^T, in which case\n",
    " the autoencoder is said to have tied weights. The network is trained such\n",
    " that to minimize the reconstruction error (the error between x and z).\n",
    "\n",
    " For the denosing autoencoder, during training, first x is corrupted into\n",
    " \\tilde{x}, where \\tilde{x} is a partially destroyed version of x by means\n",
    " of a stochastic mapping. Afterwards y is computed as before (using\n",
    " \\tilde{x}), y = s(W\\tilde{x} + b) and z as s(W'y + b'). The reconstruction\n",
    " error is now measured between z and the uncorrupted input x, which is\n",
    " computed as the cross-entropy :\n",
    "      - \\sum_{k=1}^d[ x_k \\log z_k + (1-x_k) \\log( 1-z_k)]\n",
    "\n",
    "\n",
    " References :\n",
    "   - P. Vincent, H. Larochelle, Y. Bengio, P.A. Manzagol: Extracting and\n",
    "   Composing Robust Features with Denoising Autoencoders, ICML'08, 1096-1103,\n",
    "   2008\n",
    "   - Y. Bengio, P. Lamblin, D. Popovici, H. Larochelle: Greedy Layer-Wise\n",
    "   Training of Deep Networks, Advances in Neural Information Processing\n",
    "   Systems 19, 2007\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.tensor.shared_randomstreams import RandomStreams\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#from logistic_sgd import load_data\n",
    "from run import create_network \n",
    "from run import pass_parameters \n",
    "from utils import tile_raster_images\n",
    "\n",
    "try:\n",
    "    import PIL.Image as Image\n",
    "except ImportError:\n",
    "    import Image\n",
    "\n",
    "\n",
    "class dA(object):\n",
    "    \"\"\"Denoising Auto-Encoder class (dA)\n",
    "\n",
    "    A denoising autoencoders tries to reconstruct the input from a corrupted\n",
    "    version of it by projecting it first in a latent space and reprojecting\n",
    "    it afterwards back in the input space. Please refer to Vincent et al.,2008\n",
    "    for more details. If x is the input then equation (1) computes a partially\n",
    "    destroyed version of x by means of a stochastic mapping q_D. Equation (2)\n",
    "    computes the projection of the input into the latent space. Equation (3)\n",
    "    computes the reconstruction of the input, while equation (4) computes the\n",
    "    reconstruction error.\n",
    "\n",
    "    .. math::\n",
    "\n",
    "        \\tilde{x} ~ q_D(\\tilde{x}|x)                                     (1)\n",
    "\n",
    "        y = s(W \\tilde{x} + b)                                           (2)\n",
    "\n",
    "        x = s(W' y  + b')                                                (3)\n",
    "\n",
    "        L(x,z) = -sum_{k=1}^d [x_k \\log z_k + (1-x_k) \\log( 1-z_k)]      (4)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        numpy_rng,\n",
    "        theano_rng=None,\n",
    "        input=None,\n",
    "        n_visible=784,\n",
    "        n_hidden=500,\n",
    "        W=None,\n",
    "        bhid=None,\n",
    "        bvis=None\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialize the dA class by specifying the number of visible units (the\n",
    "        dimension d of the input ), the number of hidden units ( the dimension\n",
    "        d' of the latent or hidden space ) and the corruption level. The\n",
    "        constructor also receives symbolic variables for the input, weights and\n",
    "        bias. Such a symbolic variables are useful when, for example the input\n",
    "        is the result of some computations, or when weights are shared between\n",
    "        the dA and an MLP layer. When dealing with SdAs this always happens,\n",
    "        the dA on layer 2 gets as input the output of the dA on layer 1,\n",
    "        and the weights of the dA are used in the second stage of training\n",
    "        to construct an MLP.\n",
    "\n",
    "        :type numpy_rng: numpy.random.RandomState\n",
    "        :param numpy_rng: number random generator used to generate weights\n",
    "\n",
    "        :type theano_rng: theano.tensor.shared_randomstreams.RandomStreams\n",
    "        :param theano_rng: Theano random generator; if None is given one is\n",
    "                     generated based on a seed drawn from `rng`\n",
    "\n",
    "        :type input: theano.tensor.TensorType\n",
    "        :param input: a symbolic description of the input or None for\n",
    "                      standalone dA\n",
    "\n",
    "        :type n_visible: int\n",
    "        :param n_visible: number of visible units\n",
    "\n",
    "        :type n_hidden: int\n",
    "        :param n_hidden:  number of hidden units\n",
    "\n",
    "        :type W: theano.tensor.TensorType\n",
    "        :param W: Theano variable pointing to a set of weights that should be\n",
    "                  shared belong the dA and another architecture; if dA should\n",
    "                  be standalone set this to None\n",
    "\n",
    "        :type bhid: theano.tensor.TensorType\n",
    "        :param bhid: Theano variable pointing to a set of biases values (for\n",
    "                     hidden units) that should be shared belong dA and another\n",
    "                     architecture; if dA should be standalone set this to None\n",
    "\n",
    "        :type bvis: theano.tensor.TensorType\n",
    "        :param bvis: Theano variable pointing to a set of biases values (for\n",
    "                     visible units) that should be shared belong dA and another\n",
    "                     architecture; if dA should be standalone set this to None\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        self.n_visible = n_visible\n",
    "        self.n_hidden = n_hidden\n",
    "\n",
    "        # create a Theano random generator that gives symbolic random values\n",
    "        if not theano_rng:\n",
    "            theano_rng = RandomStreams(numpy_rng.randint(2 ** 30))\n",
    "\n",
    "        # note : W' was written as `W_prime` and b' as `b_prime`\n",
    "        if not W:\n",
    "            # W is initialized with `initial_W` which is uniformely sampled\n",
    "            # from -4*sqrt(6./(n_visible+n_hidden)) and\n",
    "            # 4*sqrt(6./(n_hidden+n_visible))the output of uniform if\n",
    "            # converted using asarray to dtype\n",
    "            # theano.config.floatX so that the code is runable on GPU\n",
    "            initial_W = numpy.asarray(\n",
    "                numpy_rng.uniform(\n",
    "                    low=-4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    high=4 * numpy.sqrt(6. / (n_hidden + n_visible)),\n",
    "                    size=(n_visible, n_hidden)\n",
    "                ),\n",
    "                dtype=theano.config.floatX\n",
    "            )\n",
    "            W = theano.shared(value=initial_W, name='W', borrow=True)\n",
    "\n",
    "        if not bvis:\n",
    "            bvis = theano.shared(\n",
    "                value=numpy.zeros(\n",
    "                    n_visible,\n",
    "                    dtype=theano.config.floatX\n",
    "                ),\n",
    "                borrow=True\n",
    "            )\n",
    "\n",
    "        if not bhid:\n",
    "            bhid = theano.shared(\n",
    "                value=numpy.zeros(\n",
    "                    n_hidden,\n",
    "                    dtype=theano.config.floatX\n",
    "                ),\n",
    "                name='b',\n",
    "                borrow=True\n",
    "            )\n",
    "\n",
    "        self.W = W\n",
    "        # b corresponds to the bias of the hidden\n",
    "        self.b = bhid\n",
    "        # b_prime corresponds to the bias of the visible\n",
    "        self.b_prime = bvis\n",
    "        # tied weights, therefore W_prime is W transpose\n",
    "        self.W_prime = self.W.T\n",
    "        self.theano_rng = theano_rng\n",
    "        # if no input is given, generate a variable representing the input\n",
    "        if input is None:\n",
    "            # we use a matrix because we expect a minibatch of several\n",
    "            # examples, each example being a row\n",
    "            self.x = T.dmatrix(name='input')\n",
    "        else:\n",
    "            self.x = input\n",
    "\n",
    "        self.params = [self.W, self.b, self.b_prime]\n",
    "\n",
    "    def get_corrupted_input(self, input, corruption_level):\n",
    "        \"\"\"This function keeps ``1-corruption_level`` entries of the inputs the\n",
    "        same and zero-out randomly selected subset of size ``coruption_level``\n",
    "        Note : first argument of theano.rng.binomial is the shape(size) of\n",
    "               random numbers that it should produce\n",
    "               second argument is the number of trials\n",
    "               third argument is the probability of success of any trial\n",
    "\n",
    "                this will produce an array of 0s and 1s where 1 has a\n",
    "                probability of 1 - ``corruption_level`` and 0 with\n",
    "                ``corruption_level``\n",
    "\n",
    "                The binomial function return int64 data type by\n",
    "                default.  int64 multiplicated by the input\n",
    "                type(floatX) always return float64.  To keep all data\n",
    "                in floatX when floatX is float32, we set the dtype of\n",
    "                the binomial to floatX. As in our case the value of\n",
    "                the binomial is always 0 or 1, this don't change the\n",
    "                result. This is needed to allow the gpu to work\n",
    "                correctly as it only support float32 for now.\n",
    "\n",
    "        \"\"\"\n",
    "        return self.theano_rng.binomial(size=input.shape, n=1,\n",
    "                                        p=1 - corruption_level,\n",
    "                                        dtype=theano.config.floatX) * input\n",
    "\n",
    "    def get_hidden_values(self, input):\n",
    "        \"\"\" Computes the values of the hidden layer \"\"\"\n",
    "        return T.nnet.sigmoid(T.dot(input, self.W) + self.b)\n",
    "\n",
    "    def get_reconstructed_input(self, hidden):\n",
    "        \"\"\"Computes the reconstructed input given the values of the\n",
    "        hidden layer\n",
    "\n",
    "        \"\"\"\n",
    "        return T.nnet.sigmoid(T.dot(hidden, self.W_prime) + self.b_prime)\n",
    "\n",
    "    def get_cost_updates(self, corruption_level, learning_rate):\n",
    "        \"\"\" This function computes the cost and the updates for one trainng\n",
    "        step of the dA \"\"\"\n",
    "\n",
    "        tilde_x = self.get_corrupted_input(self.x, corruption_level)\n",
    "        y = self.get_hidden_values(tilde_x)\n",
    "        print(\"hidden Shape : \", y.eval())\n",
    "        \n",
    "        z = self.get_reconstructed_input(y)\n",
    "        # note : we sum over the size of a datapoint; if we are using\n",
    "        #        minibatches, L will be a vector, with one entry per\n",
    "        #        example in minibatch\n",
    "        L = - T.sum(self.x * T.log(z) + (1 - self.x) * T.log(1 - z), axis=1)\n",
    "        # note : L is now a vector, where each element is the\n",
    "        #        cross-entropy cost of the reconstruction of the\n",
    "        #        corresponding example of the minibatch. We need to\n",
    "        #        compute the average of all these to get the cost of\n",
    "        #        the minibatch\n",
    "        cost = T.mean(L)\n",
    "\n",
    "        # compute the gradients of the cost of the `dA` with respect\n",
    "        # to its parameters\n",
    "        gparams = T.grad(cost, self.params)\n",
    "        # generate the list of updates\n",
    "        updates = [\n",
    "            (param, param - learning_rate * gparam)\n",
    "            for param, gparam in zip(self.params, gparams)\n",
    "        ]\n",
    "\n",
    "        return (cost, updates)\n",
    "\n",
    "\n",
    "def test_dA(learning_rate = 0.1, training_epochs = 10,\n",
    "            dataset = numpy.random.random((100,100)) ,\n",
    "            batch_size = 20, output_folder = 'dA_plots'): \n",
    "\n",
    "    \"\"\"\n",
    "    This demo is tested on MNIST \n",
    "\n",
    "    :type learning_rate: float \n",
    "    :param learning_rate: learning rate used for training the DeNosing \n",
    "                          AutoEncoder\n",
    "\n",
    "    :type training_epochs: int\n",
    "    :param training_epochs: number of epochs used for training\n",
    "\n",
    "    :type dataset: string\n",
    "    :param dataset: path to the picked dataset\n",
    "\n",
    "    \"\"\"\n",
    "    \n",
    "    lr, epochs, dataSet, batch_s, out_folder = pass_parameters()\n",
    "    \n",
    "    learning_rate = lr\n",
    "    training_epochs = epochs\n",
    "    dataset = dataSet \n",
    "    batch_size = batch_s\n",
    "    output_folder = out_folder\n",
    "    \n",
    "    print(dataset)\n",
    "    \n",
    "    train_set_x = dataset\n",
    "\n",
    "    # compute number of minibatches for training, validation and testing\n",
    "    n_train_batches = train_set_x.get_value(borrow=True).shape[0] // batch_size\n",
    "\n",
    "    # start-snippet-2\n",
    "    # allocate symbolic variables for the data\n",
    "    index = T.lscalar()    # index to a [mini]batch\n",
    "    x = T.matrix('x')  # the data is presented as rasterized images\n",
    "    # end-snippet-2\n",
    "\n",
    "    if not os.path.isdir(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    os.chdir(output_folder)\n",
    "\n",
    "    ####################################\n",
    "    # BUILDING THE MODEL NO CORRUPTION #\n",
    "    ####################################\n",
    "\n",
    "    print(\"Building model with 0 percent Corruption...... \")\n",
    "\n",
    "    rng = numpy.random.RandomState(123)\n",
    "    theano_rng = RandomStreams(rng.randint(2 ** 30))\n",
    "\n",
    "    n_visible, n_hidden, corruption_level = create_network()\n",
    "\n",
    "\n",
    "    da = dA(\n",
    "        numpy_rng=rng,\n",
    "        theano_rng=theano_rng,\n",
    "        input=x,\n",
    "        n_visible= n_visible,\n",
    "        n_hidden= n_hidden\n",
    "    )\n",
    "\n",
    "    cost, updates = da.get_cost_updates(\n",
    "        corruption_level=corruption_level,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "\n",
    "    train_da = theano.function(\n",
    "        [index],\n",
    "        cost,\n",
    "        updates=updates,\n",
    "        givens={\n",
    "            x: train_set_x[index * batch_size: (index + 1) * batch_size]\n",
    "        }\n",
    "    )\n",
    "\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "    ############\n",
    "    # TRAINING #\n",
    "    ############\n",
    "\n",
    "    # go through training epochs\n",
    "    for epoch in range(training_epochs):\n",
    "        # go through trainng set\n",
    "        c = []\n",
    "        for batch_index in range(n_train_batches):\n",
    "            c.append(train_da(batch_index))\n",
    "\n",
    "        print('Training epoch %d, cost ' % epoch, numpy.mean(c))\n",
    "\n",
    "    end_time = timeit.default_timer()\n",
    "    \n",
    "    training_time = (end_time - start_time)\n",
    "    \n",
    "    print(('The no corruption code for file ' +\n",
    "           os.path.split('__file__')[1] +\n",
    "           ' ran for %.2fm' % ((training_time) / 60.)), file=sys.stderr)\n",
    "\n",
    "    image = Image.fromarray(\n",
    "        tile_raster_images(X=da.W.get_value(borrow=True).T,\n",
    "                           img_shape=(64, 64), tile_shape=(10, 10),\n",
    "                           tile_spacing=(1, 1)))\n",
    "    #image.save('filters_corruption_0.png')\n",
    "    \n",
    "    fil = da.W.get_value(borrow=True).T\n",
    "    print(\"Learned filter : \", fil)\n",
    "    print(fil.shape)\n",
    "    fil = numpy.reshape(fil[0,:], (64,64))\n",
    "    print(fil)\n",
    "    print(fil.shape)\n",
    "    \n",
    "    print(\"W_prime : \", da.W_prime.eval())\n",
    "    print(\"W_prime shape : \", da.W_prime.shape.eval())\n",
    "    \n",
    "    %matplotlib inline\n",
    "    plt.imshow(fil, cmap='Greys_r')\n",
    "    plt.colorbar()\n",
    "    \n",
    "    #Display reconstruction images\n",
    "    \n",
    "    \n",
    "    \n",
    "    os.chdir('../')\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    test_dA()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/global/common/cori/software/theano/0.8.2/lib/python2.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0,'/global/common/cori/software/lasagne/0.1/lib/python2.7/site-packages/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lasagne' from '/global/common/cori/software/lasagne/0.1/lib/python2.7/site-packages/lasagne/__init__.py'>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0,'/global/common/cori/software/theano/0.8.2/lib/python2.7/site-packages/')\n",
    "import theano\n",
    "sys.path.insert(0,'/global/common/cori/software/lasagne/0.1/lib/python2.7/site-packages/')\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
