{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "... loading data\n",
      "Printing Train set  [[-0.01032324  0.00679525  0.0022744  ...,  0.03324072  0.00723581\n",
      "  -0.02659455]\n",
      " [-0.00930681 -0.0276424  -0.0210422  ...,  0.0203146   0.0402362\n",
      "   0.02766863]\n",
      " [ 0.0404234   0.04943935  0.03146164 ..., -0.01016859 -0.01045878\n",
      "  -0.01592986]\n",
      " ..., \n",
      " [-0.0090084  -0.02353951 -0.0269437  ..., -0.02338999 -0.00726545\n",
      "  -0.01155015]\n",
      " [-0.01656553 -0.00560305  0.0130041  ..., -0.03842881  0.00073663\n",
      "  -0.00430508]\n",
      " [-0.03468535 -0.03392641 -0.038837   ...,  0.01248583  0.0289001\n",
      "  -0.00986743]]\n",
      "X_train shape  (1000, 1048576)\n",
      "Printing shared_dataset  <TensorType(float64, matrix)>\n",
      "Final Training Set  <TensorType(float64, matrix)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<TensorType(float64, matrix)>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is a class we will use for Loading the Data for an Autoencoder. Since the training is unsupervised, \n",
    "# all we care about is the Training inputs and not training labels. \n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "__docformat__ = 'restructedtext en'\n",
    "\n",
    "import h5py\n",
    "import os\n",
    "import sys\n",
    "import timeit\n",
    "\n",
    "import numpy as np \n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "\n",
    "\n",
    "def load_data(dataset):\n",
    "    ''' Loads the dataset\n",
    "\n",
    "    :type dataset: string\n",
    "    '''\n",
    "    #############\n",
    "    # LOAD DATA #\n",
    "    #############\n",
    "\n",
    "    print('... loading data')\n",
    "\n",
    "    # Load the dataset\n",
    "    \n",
    "    with h5py.File(dataset,'r') as hf: \n",
    "        #train_set = hf['X_train'][0:1000,0:65536]\n",
    "        train_set = hf['data_mean_diff_abs'][0:1000,0:4096]\n",
    "        print(\"Printing Train set \", train_set) \n",
    "        print(\"X_train shape \", train_set.shape)\n",
    "        \n",
    "    # train_set format: tuple(input)\n",
    "    # input is a numpy.ndarray of 2 dimensions (a matrix)\n",
    "    # where each row corresponds to an example. target is a\n",
    "    # numpy.ndarray of 1 dimension (vector) that has the same length as\n",
    "    # the number of rows in the input. It should give the target\n",
    "    # to the example with the same index in the input. (Sorry no labels)\n",
    "\n",
    "    def shared_dataset(data_x, borrow=True): \n",
    "        \"\"\" Function that loads the dataset into shared variables\n",
    "\n",
    "        The reason we store our dataset in shared variables is to allow\n",
    "        Theano to copy it into the GPU memory (when code is run on GPU).\n",
    "        Since copying data into the GPU is slow, copying a minibatch everytime\n",
    "        is needed (the default behaviour if the data is not in a shared\n",
    "        variable) would lead to a large decrease in performance.\n",
    "        \"\"\"\n",
    "    #   data_x, data_y = data_xy\n",
    "        shared_x = theano.shared(np.asarray(data_x,\n",
    "                                               dtype=theano.config.floatX),\n",
    "                                               borrow=borrow)\n",
    "        print(\"Printing shared_dataset \", shared_x)\n",
    "    \n",
    "        return shared_x \n",
    "\n",
    "    train_set_x = shared_dataset(train_set)\n",
    "    print(\"Final Training Set \", train_set_x)\n",
    "    return train_set_x \n",
    "\n",
    "#load_data('/global/homes/s/ssingh79/data/conv_z02.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
